{
    "collab_server" : "",
    "contents" : "# This code supports the analysis of the impact of smoke from wood heaters.\n\n# ---- import_packages ---------------------------------------------------------\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(readxl)\nlibrary(lubridate)\nlibrary(raster)\nlibrary(rgdal)\nlibrary(rgeos)\nlibrary(maptools)\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(ggmap)\nlibrary(xtable)\nlibrary(viridis)\n\n# ---- untar_raw_csiro_data -----------------------------------------------\n# This script decompresses the CSIRO .csv files, replicating the dropbox directory\n# structure within the working directory.\n\n# Depends of the tar.gz files uploaded by CSIRO to the dropbox folder.\n\n# Set the directory containing the zip data.\ncsiro_data_dir <- \"~/Dropbox/Woolcock\"\n\n# Make a list of all the tar.gz files.\ngz_files <- list.files(csiro_data_dir, \"tar.gz\", recursive=TRUE)\n\n# Unzip them, replicating the directory structure with the working directory\nfor(i in seq_along(gz_files)){\n  untar(paste0(csiro_data_dir, \"/\", gz_files[i]), exdir = gsub(\"tar.gz\", \"\", gz_files[i]))\n}\n# Clear the global environment\nrm(list = ls())\n\n\n# ---- rasters ------------------------------------------------------\n# This script turns the CSIRO .csv files into rasters.\n\n# Load the make_raster function\nsource(\"src/make_raster.R\")\n\n# Make a vector of all csv files in the directory.\nfiles <- list.files(pattern = \".csv\", recursive=TRUE)\n\n# Remove any related to the first of each month\nfiles <- files[!grepl(\"01_s\", files)]\n\n# Split them into a list of 1km and 3km\nfiles_1km <- files[grepl(\"1km\", files)]\nfiles_3km <- files[grepl(\"3km\", files)]\n\n# Make list of vectors of files for each scenario and grid resolution\nscenarios_1km <- list(s20 = files_1km[grepl(\"_s20\", files_1km)],\n                      s21 = files_1km[grepl(\"_s21\", files_1km)],\n                      s22 = files_1km[grepl(\"_s22\", files_1km)],\n                      s23 = files_1km[grepl(\"_s23\", files_1km)],\n                      s24 = files_1km[grepl(\"_s24\", files_1km)])\n\nscenarios_3km <- list(s20 = files_3km[grepl(\"_s20\", files_3km)],\n                      s21 = files_3km[grepl(\"_s21\", files_3km)],\n                      s22 = files_3km[grepl(\"_s22\", files_3km)],\n                      s23 = files_3km[grepl(\"_s23\", files_3km)],\n                      s24 = files_3km[grepl(\"_s24\", files_3km)])\n\n# Rasterize the csv files (using the average_raster function from\n# \"raster_functions.R\"). The output is a list of rasters.\nrasters_1km <- parallel::mclapply(scenarios_1km, FUN = make_raster, mc.cores = 5)\nrasters_3km <- parallel::mclapply(scenarios_3km, FUN = make_raster, mc.cores = 5)\n\n# Make the 3km rasters into 1km resolution (ie break each square up 3 x 3)\nrasters_3km <- lapply(rasters_3km, FUN = raster::disaggregate, fact = 3)\n\n# Merge the five resulting rasters and make a list of them\nrasters <- list()\nfor(i in seq_along(rasters_1km)){\n  rasters[[i]] <- raster::merge(rasters_1km[[i]], rasters_3km[[i]])\n}\nnames(rasters) <- names(scenarios_1km)\n\n# Save them to the /rasters folder\nfor(i in seq_along(rasters)){\n  raster::writeRaster(rasters[[i]], paste0(\"rasters/\", names(rasters)[i], \".tif\"), overwrite = TRUE)\n}\n\n# Clear the global environment\nrm(make_raster, files, files_1km, files_3km,\n   scenarios_1km, rasters_1km, rasters_3km,\n   scenarios_3km, i)\n\n# ---- ap_poly ------------------------------------------------------\n# Extract data from raster files to SA1 polygons\n\n# Depends on the 5 rasters in the /rasters folder\n\n# Load rasters\n# tif_files <- list.files(\"rasters\")\n# rasters <- lapply(paste0(\"rasters/\", tif_files), raster::raster)\n# names(rasters) <- gsub(\".tif\", \"\", tif_files)\n\n# Load a map or SA1s. Source: ABS statistical geography website.\nmap     <- rgdal::readOGR(\"shp\", \"SA1_2011_AUST\")\nsa2_map <- rgdal::readOGR(\"shp\", \"SydGMR_SA2_inclusive\")\n# Subset to the sa2_map\nmap     <- map[map$SA2_MAIN11 %in% sa2_map$SA2_MAIN11, ]\n\n# Make SA1-level averages (area weighted) of the rasters\nsa1_averages <- parallel::mclapply(rasters, FUN = raster::extract,\n                                   y = map, fun = mean, weights = TRUE,\n                                   mc.cores=5)\n\n# Bind them to the polygons\nap_poly <- map\nap_poly@data <- cbind(ap_poly@data, s20 = sa1_averages[[1]], s21 = sa1_averages[[2]],\n                  s22 = sa1_averages[[3]], s23 = sa1_averages[[4]], s24 = sa1_averages[[5]])\nrgdal::writeOGR(ap_poly, \"shp\", \"ap_poly\", driver = \"ESRI Shapefile\", overwrite_layer = TRUE)\n\n# Tidy up\nrm(map, tif_files, rasters, sa2_map)\ndetach(package:raster, unload = TRUE)\n\n# ---- exposure_data -------------------------------------------------\n# Calculate population weighted concentrations\n\n# Depends on shp/ap_poly.shp\n\n# Get the ap data and the list of study area SA1s from map\nsa1s <- ap_poly@data\nnames(sa1s) <- tolower(names(sa1s))\nsa1s$sa1_main11 <- as.numeric(as.character(sa1s$sa1_main11))\nsa1s$sa1_7dig11 <- as.numeric(as.character(sa1s$sa1_7dig11))\n\n# Create the actual scenarios - e.g. all emissions = s5 - s6, low-s fuel everywhere = s5 - s7\nsa1_pm <- sa1s %>%\n  mutate(all_heaters = s20 - s21,\n         s1 = s20 - s22,\n         s2 = s20 - s23,\n         all_anthropogenic = s20 - s24)\n\n# Load population data and subset it to the relevant SA1s\npop <- readr::read_csv(\"pop_deaths_data/sa1_pop_seifa.csv\")\npop$irsd <- ifelse(pop$irsd == 0, NA, pop$irsd)\n\n# Merge population and all three datasets\nall_data <- pop %>%\n  inner_join(sa1_pm, by = c(\"sa1_code\" = \"sa1_7dig11\")) %>%\n  dplyr::select(1:4, 13, 18:26)\n\n# Overall population weighting\ntotal <- all_data %>%\n  mutate(pop_weight = population / sum(population)) %>%\n  summarise(all_pm = sum(pop_weight * s20),\n            all_anthropogenic = sum(pop_weight * all_anthropogenic),\n            all_heaters = sum(pop_weight * all_heaters),\n            s1 = sum(pop_weight * s1),\n            s2 = sum(pop_weight * s2)) %>%\n  mutate(irsd = NA, gcc_code11 = \"All NSW\")\n\ntotal_syd <- all_data %>%\n  group_by(gcc_code11) %>%\n  mutate(pop_weight = population / sum(population)) %>%\n  summarise(all_pm = sum(pop_weight * s20),\n            all_anthropogenic = sum(pop_weight * all_anthropogenic),\n            all_heaters = sum(pop_weight * all_heaters),\n            s1 = sum(pop_weight * s1),\n            s2 = sum(pop_weight * s2)) %>%\n  mutate(irsd = NA)\n\n# IRSD only\nirsd <- all_data %>%\n  filter(!is.na(irsd)) %>%\n  group_by(irsd) %>%\n  mutate(pop_weight = population / sum(population)) %>%\n  summarise(all_pm = sum(pop_weight * s20),\n            all_anthropogenic = sum(pop_weight * all_anthropogenic),\n            all_heaters = sum(pop_weight * all_heaters),\n            s1 = sum(pop_weight * s1),\n            s2 = sum(pop_weight * s2)) %>%\n  mutate(gcc_code11 = rep(\"All NSW\", nrow(.)))\n\nirsd_syd <- all_data %>%\n  filter(!is.na(irsd)) %>%\n  group_by(irsd, gcc_code11) %>%\n  mutate(pop_weight = population / sum(population)) %>%\n  summarise(all_pm = sum(pop_weight * s20),\n            all_anthropogenic = sum(pop_weight * all_anthropogenic),\n            all_heaters = sum(pop_weight * all_heaters),\n            s1 = sum(pop_weight * s1),\n            s2 = sum(pop_weight * s2))\n\nexposure_data <- bind_rows(total, total_syd, irsd, irsd_syd)\n\nall_pm <- exposure_data[[1, 1]]\nall_anthropogenic <- exposure_data[[1, 2]]\nall_heaters <- exposure_data[[1, 3]]\n\nrm(total, total_syd, irsd, irsd_syd, all_data, pop, sa1s)\n\n# ---- health_data ----------------------------------------------------\n# Make a list of unique SA2s in the study area from the map\ngeog <- ap_poly\ngeog <- geog@data[, c(3, 10)]\nnames(geog) <- tolower(names(geog))\ngeog <- unique(geog)\ngeog$sa2_main11 = as.numeric(as.character(geog$sa2_main11))\n\n\n# Load SA2 seifa and remove SA2s outside study area\nseifa <- readr::read_csv(\"pop_deaths_data/sa2_seifa.csv\", na = \"-\")\nseifa <- seifa %>% filter(sa2_code %in% geog$sa2_main11)\n\n# Load the population and death data - this is 3 years data: 2009 - 2011\ndeaths <- readr::read_csv(\"pop_deaths_data/pop_deaths_sa2_2009-2011_fy.csv\")\n\n# Merge the deaths, population and seifa data\nall_data <- deaths %>%\n  group_by(age, sa2_2011) %>%\n  summarise(deaths = sum(deaths)/3,\n            population = sum(population)/3) %>%\n  filter(sa2_2011 %in% geog$sa2_main11) %>%\n  left_join(seifa, by = c(\"sa2_2011\" = \"sa2_code\")) %>%\n  left_join(geog, by = c(\"sa2_2011\" = \"sa2_main11\"))\n\n# Calculate the rates\n\n# Calculate the AGE specific rates.\nage <- all_data %>%\n  group_by(age) %>%\n  summarise(population = sum(population),\n            deaths = sum(deaths)) %>%\n  mutate(irsd = rep(NA, nrow(.)),\n         gcc_code11 = rep(\"All NSW\", nrow(.)))\n\nage_syd <- all_data %>%\n  group_by(age, gcc_code11) %>%\n  summarise(population = sum(population),\n            deaths = sum(deaths)) %>%\n  mutate(irsd = rep(NA, nrow(.)))\n\n#write_csv(age, \"data_for_analysis/age_data.csv\")\n\n# AGE IRSD\nirsd_age <- all_data %>%\n  filter(!is.na(irsd)) %>%\n  group_by(age, irsd) %>%\n  summarise(population = sum(population),\n            deaths = sum(deaths)) %>%\n  ungroup() %>%\n  mutate(gcc_code11 = rep(\"All NSW\", nrow(.)))\n\nirsd_age_syd <- all_data %>%\n  filter(!is.na(irsd)) %>%\n  group_by(age, irsd, gcc_code11) %>%\n  summarise(population = sum(population),\n            deaths = sum(deaths)) %>%\n  ungroup()\n\nhealth_data <- bind_rows(age, age_syd, irsd_age, irsd_age_syd)\n\nall_data <- left_join(health_data, exposure_data, by = c(\"irsd\", \"gcc_code11\"))\n\n# Clean up\nrm(age, age_syd, irsd_age, irsd_age_syd, deaths, geog, seifa, health_data, exposure_data)\n\n# ---- burden_results -------------------------------------------------\n# Function to calculate burden\ncalculate_burden <- function(df, RR = 1.062, increment = 10){\n  # Function to calculate loss of life expectancy, attributable number and YLL\n  # associated with a given PM2.5 concentration. Takes a vector of single-year\n  # population size (ages 0 - 85+), single year deaths (ages 0 - 85+) and the\n  # PM2.5 concentration of interest.\n\n  d <- df %>% arrange(age)\n\n  # Calculate the RR associated with the change in PM2.5\n  beta <- log(RR)/increment # Beta coefficient\n\n  # Calculate baseline hazard and the hazard if there was less PM2.5\n  Mx <- d$deaths / d$population\n  Mx_less_exposed <- c(Mx[1:30], Mx[31:length(Mx)] * exp(-beta*d$pm[31:length(Mx)]))  # Risk only increased for those > 30\n\n  # Function to calculate life expectancy from the hazard\n  life_expectancy <- function(hazard){\n    start.age <- 0:85\n    end.age <- c(1:85, 96)\n    n <- end.age-start.age\n    ax <- c(0.1, rep(0.5, length(n) - 1))\n    qx <- (n*hazard)/(1+n*(1-ax)*hazard) # Estimate mortality rates from hazard\n    qx[length(qx)] <- 1\n    px <- 1 - qx\n    x <- cumprod(px)\n    Ix <- 100000*(c(1, cumprod(px[1:(length(px)-1)])))\n    Ix.lag <- c(Ix[2:length(Ix)],0)\n    dx <- Ix-Ix.lag\n    Lx <- n*(Ix.lag + (ax*dx))\n    Lx[length(Lx)] <- dx[length(dx)]/Mx[length(Mx)]\n    Tx <- rev(cumsum(rev(Lx)))\n    ex <- Tx/Ix\n  }\n\n  le_current <- life_expectancy(Mx)\n  le_less_exposed <- life_expectancy(Mx_less_exposed)\n  lost_le = le_less_exposed - le_current\n\n  # Calculate attributable number and the YLL\n  attributable_n = d$deaths / d$population * (1 - exp(-beta * d$pm)) * d$population\n  yll <- attributable_n * le_less_exposed\n\n  # Make a list of the key results\n  results <- list(\n    \"Additional risk of mortality attributabale to 2010/11 exposure (%)\" = round(100 * (1 - exp(-beta * d$pm[1])), 1) %>% as.character,\n    \"Population attributable fraction (%)\" = round(100 * sum(attributable_n[31:length(attributable_n)]) / sum(d$deaths), 1) %>% as.character(),\n    \"Loss of life expectancy at age 30 (days)\" = round(lost_le[31] * 365, 1) %>% as.character(),\n    \"Attributable number (n)\" = round(sum(attributable_n[31:length(attributable_n)])) %>% as.character(), # 0nly 30+\n    \"YLL (years)\" = round(sum(yll[31:length(attributable_n)])) %>% format(big.mark = \",\")#,\n    # \"Loss of life expectancy at birth (days)\" = round(lost_le[1] * 365, 1),\n    # \"Loss of life expectancy at 65 (days)\" = round(lost_le[66] * 365, 1),\n    # \"YLL [Method 2] (Years)\" = round(sum(d$deaths * lost_le)),\n    # \"YLL [Method 3] (Years)\" = format(round(sum(d$population * lost_le)), big.mark=\",\")\n  )\n  results\n}\n\n# x <- health_data %>%\n#   filter(is.na(irsd), gcc_code11 == \"All NSW\") %>%\n#   dplyr::select(1:3) %>%\n#   mutate(pm = rep(pw_pm[[1, 3]], nrow(.)))\n\nx <- all_data %>%\n  filter(is.na(irsd), gcc_code11 == \"All NSW\") %>%\n  dplyr::select(age, population, deaths, pm = all_heaters)\n\nburden_results <- lapply(X = c(1.062, 1.04, 1.08), FUN = calculate_burden, df = x, increment = 10) %>%\n  bind_rows() %>% t() %>% data.frame(stringsAsFactors=FALSE)\nburden_results[,2] <- paste0(burden_results[,2], \" -- \", burden_results[,3])\nburden_results <- burden_results[,-3] %>% data.frame(stringsAsFactors=FALSE)\n# burden_results[, 1:2] <- apply(burden_results[, 1:2], 2, str_trim)\nnames(burden_results) = c(\"Estimate\", \"95% CI\")\nrm(x)\n\n# ---- burden_table -------------------------------------------------------\nx <- xtable(burden_results)\nprint(x, comment=FALSE, size = \"footnotesize\", floating=FALSE, booktabs=TRUE)\n\n\n# ---- impact_results ------------------------------------------------\n# Function to calculate impact\ncalculate_impact  <- function(df, scenario, RR = 1.062, increment = 10, cessation_lag = \"us epa\", year = NULL){\n  d <- df %>% arrange(age) %>% data.frame()\n  population <-  d$population\n  deaths <- d$deaths\n  # Preliminaries:\n  # Beta coefficient\n  b <- log(RR)/increment\n  # Set the ages\n  ages <- 0:110\n  # Get the exposure variable\n  ap <- d[, scenario]\n  ap <- c(ap, rep(ap[length(ap)], length(ages) - length(ap)))\n\n  # Baseline calculations\n\n  # Matrix of survival probabilities for the baseline\n  qx <- d$deaths / d$population\n  qqx <- c(qx, rep(qx[length(qx)], length(ages) - length(qx)))\n  sx <- (2 - qqx) / (2 + qqx)\n  sx[length(sx)] <- 0\n  sx_mat <- matrix(rep(c(head(sx, -1), 0), length(ages)),\n                   nrow = length(ages), ncol = length(ages))\n\n  # Matrix of baseline population into the future\n  nx0 <- c(population, rep(0, length(ages) - length(population)))\n  SSX <- diag(head(sx, - 1))\n  r1 <- rep(c(1,0), c(1, length(ages) - 2))\n  SX1 <- cbind(rbind(r1, SSX), rep(0, length(ages)))\n  pop_mat <- matrix(0, ncol = length(ages) - 1, nrow = length(ages))\n  y <- vector(\"list\", length(ages) - 1)\n  y[[1]] <- SX1\n  for(i in 1:(length(y) - 1)){\n    y[[i+1]] <- y[[i]] %*% SX1\n  }\n  for(i in 1:length(y)){\n    pop_mat[, i] <- y[[i]] %*% nx0\n  }\n  base_pop <- cbind(nx0, pop_mat)\n\n  # Impacted calculations\n  # No cessation lag\n  if(is.null(cessation_lag)){\n    # Matrix of survival probabilites for the reduced exposure\n    qqx_i <- c(qqx[1:30], qqx[31:length(ages)] * 1/exp(b*ap[31:length(ages)]))\n    sx_i <- (2 - qqx_i) / (2 + qqx_i)\n    sx_i[length(sx_i)] <- 0\n    sx_mat_i <- matrix(rep(c(head(sx_i, -1), 0), length(ages)),\n                       nrow = length(ages), ncol = length(ages))\n\n    # Matrix of reduced exposure population into the future\n    SSX_i <- diag(head(sx_i, - 1))\n    SX1_i <- cbind(rbind(r1, SSX_i), rep(0, length(ages)))\n    pop_mat <- matrix(0, ncol = length(ages) - 1, nrow = length(ages))\n    y <- vector(\"list\", length(ages) - 1)\n    y[[1]] <- SX1_i\n    for(i in 1:(length(y) - 1)){\n      y[[i+1]] <- y[[i]] %*% SX1_i\n    }\n    for(i in 1:length(y)){\n      pop_mat[, i] <- y[[i]] %*% nx0\n    }\n    impact_pop <- cbind(nx0, pop_mat)\n  }\n\n  # Numeric cessation_lag\n  if(class(cessation_lag) == \"numeric\"){\n    m1 <- matrix(0, nrow = length(ages), ncol = length(1:cessation_lag))\n    for(i in 1:ncol(m1)){\n      x <- 1 / rev(1:cessation_lag)[i]\n      rr  <-  c(rep(1, 30), 1/exp(b*ap[31:length(ages)]))\n      # rr <- c(rr, rep(rr[length(rr)], length(ages) - length(rr)))\n      rr  <- 1 - ((1 - rr) * x)\n      m1[, i] <- c(qqx[1:30], qqx[31:length(ages)]) * rr\n    }\n    qqx_i <- c(qqx[1:30], qqx[31:length(ages)] * 1/exp(b*ap[31:length(ages)]))\n    m2 <- matrix(rep(qqx_i, length(ages) - ncol(m1)), nrow = length(ages),\n                 ncol = length(ages) - ncol(m1))\n    qqx_mat_i <- cbind(m1, m2)\n    sx_mat_i <- (2 - qqx_mat_i)/(2+qqx_mat_i)\n    sx_mat_i[nrow(sx_mat_i),] <- rep(0, ncol(sx_mat_i))\n\n    y[[1]] <- sx_mat_i[,1]\n    r1 <- rep(c(1,0), c(1, length(ages) - 2))\n    for(i in 2:(ncol(sx_mat_i) - 1)){\n      SSX <- diag(head(sx_mat_i[,i], -1))\n      SX1 <- cbind(rbind(r1,SSX), rep(0, length(ages)))\n      y[[i]] <- y[[i - 1]] %*% SX1\n    }\n\n\n    # Matrix of reduced exposure population into the future\n    sx_arr <- array(0, dim = c(nrow(sx_mat_i), ncol(sx_mat_i), length(ages)))\n    for(i in 1:dim(sx_arr)[3]){\n      x <- diag(head(sx_mat_i[,i], -1))\n      x <- cbind(rbind(r1, x), rep(0, length(ages)))\n      sx_arr[, , i] <- x\n    }\n    pop_mat <- matrix(0, ncol = length(ages) - 1, nrow = length(ages))\n    y <- vector(\"list\", length(ages) - 1)\n    y[[1]] <- sx_arr[ , , 1]\n    for(i in 1:(length(y) - 1)){\n      y[[i+1]] <- y[[i]] %*% sx_arr[ , , i+1]\n    }\n    for(i in 1:length(y)){\n      pop_mat[, i] <- y[[i]] %*% nx0\n    }\n    impact_pop <- cbind(nx0, pop_mat)\n  }\n\n  # US EPA cessation_lag\n  if(class(cessation_lag) == \"character\"){\n    # m1 <- matrix(0, nrow = length(ages), ncol = 20)\n    rr  <-  c(rep(1, 30), 1/exp(b*ap[31:length(ages)]))\n    s <- c(seq(0.3, 0.8, 0.125), seq(0.8, 1, length.out = 15))\n    lag_rr <- function(rr, s){\n      x <- 1 - ((1 - rr) * s)\n      x\n    }\n    rrs <- sapply(s, lag_rr, rr = rr)\n    m1 <- matrix(rep(c(qqx[1:30], qqx[31:length(ages)]), 20), ncol = 20)\n    m1 <- m1*rrs\n\n    qqx_i <- c(qqx[1:30], qqx[31:length(ages)] * 1/exp(b*ap[31:length(ages)]))\n    m2 <- matrix(rep(qqx_i, length(ages) - ncol(m1)), nrow = length(ages),\n                 ncol = length(ages) - ncol(m1))\n    qqx_mat_i <- cbind(m1, m2)\n    sx_mat_i <- (2 - qqx_mat_i)/(2+qqx_mat_i)\n    sx_mat_i[nrow(sx_mat_i),] <- rep(0, ncol(sx_mat_i))\n\n    y[[1]] <- sx_mat_i[,1]\n    r1 <- rep(c(1,0), c(1, length(ages) - 2))\n    for(i in 2:(ncol(sx_mat_i) - 1)){\n      SSX <- diag(head(sx_mat_i[,i], -1))\n      SX1 <- cbind(rbind(r1,SSX), rep(0, length(ages)))\n      y[[i]] <- y[[i - 1]] %*% SX1\n    }\n\n\n    # Matrix of reduced exposure population into the future\n    sx_arr <- array(0, dim = c(nrow(sx_mat_i), ncol(sx_mat_i), length(ages)))\n    for(i in 1:dim(sx_arr)[3]){\n      x <- diag(head(sx_mat_i[,i], -1))\n      x <- cbind(rbind(r1, x), rep(0, length(ages)))\n      sx_arr[, , i] <- x\n    }\n    pop_mat <- matrix(0, ncol = length(ages) - 1, nrow = length(ages))\n    y <- vector(\"list\", length(ages) - 1)\n    y[[1]] <- sx_arr[ , , 1]\n    for(i in 1:(length(y) - 1)){\n      y[[i+1]] <- y[[i]] %*% sx_arr[ , , i+1]\n    }\n    for(i in 1:length(y)){\n      pop_mat[, i] <- y[[i]] %*% nx0\n    }\n    impact_pop <- cbind(nx0, pop_mat)\n  }\n\n  # Sums to estimate totals\n\n  base_pop1 <- base_pop[-nrow(base_pop), -ncol(base_pop)]\n  base_pop2 <- base_pop[-1, -1]\n  base_deaths <- base_pop1 - base_pop2\n  base_ly <- base_pop[1:nrow(base_deaths), 1:nrow(base_deaths)] - 0.5 * base_deaths\n\n  impact_pop1 <- impact_pop[-nrow(impact_pop), -ncol(impact_pop)]\n  impact_pop2 <- impact_pop[-1, -1]\n  impact_deaths <- impact_pop1 - impact_pop2\n  impact_ly <- impact_pop[1:nrow(impact_deaths), 1:nrow(impact_deaths)] - 0.5 * impact_deaths\n\n  deaths <- colSums(base_deaths) - colSums(impact_deaths)\n  lys <- colSums(impact_ly) - colSums(base_ly)\n  cumlys <- cumsum(lys)\n\n  results <- data.frame(deaths = deaths, life_years = lys, cum_lys = cumlys)[1:105,]\n  results\n}\n\n# x <- health_data %>%\n#   filter(is.na(irsd), gcc_code11 == \"All NSW\") %>%\n#   dplyr::select(1:3) %>%\n#   mutate(pm = rep(pw_pm[[1, 4]], nrow(.)))\n\nx <- all_data %>%\n  filter(is.na(irsd), gcc_code11 == \"All NSW\") %>%\n  dplyr::select(age, population, deaths, pm = s1)\n\nimpact_s1 <- lapply(X = c(1.062, 1.04, 1.08), FUN = calculate_impact, df = x,\n                    scenario = \"pm\", increment = 10,\n                    cessation_lag = \"us epa\", year = NULL)\nimpact_s1 <- bind_cols(impact_s1) %>% round() %>% format(big.mark = \",\")\nimpact_s1 <- apply(impact_s1, 2, FUN = str_trim) %>% data.frame(stringsAsFactors=FALSE)\n\nx <- all_data %>%\n  filter(is.na(irsd), gcc_code11 == \"All NSW\") %>%\n  dplyr::select(age, population, deaths, pm = s2)\n\nimpact_s2 <- lapply(X = c(1.062, 1.04, 1.08), FUN = calculate_impact, df = x,\n                    scenario = \"pm\", increment = 10,\n                    cessation_lag = \"us epa\", year = NULL)\nimpact_s2 <- bind_cols(impact_s2) %>% round() %>% format(big.mark = \",\")\nimpact_s2 <- apply(impact_s2, 2, FUN = str_trim) %>% data.frame(stringsAsFactors=FALSE)\n\nimpact_results <- data.frame(col1 = c(\"Heaters emit 2.5g/kg\", \"Heaters emit 1.5g/kg\"),\n                             col2 = paste0(c(impact_s1[5, 3], impact_s2[5, 3]),\n                                           \" (\", c(impact_s1[5, 6], impact_s2[5, 6]),\n                                           \" -- \", c(impact_s1[5, 9], impact_s2[5, 9]), \")\"),\n                             col3 = paste0(c(impact_s1[10, 3], impact_s2[10, 3]),\n                                           \" (\", c(impact_s1[10, 6], impact_s2[10, 6]),\n                                           \" -- \", c(impact_s1[10, 9], impact_s2[10, 9]), \")\"),\n                             col4 = paste0(c(impact_s1[20, 3], impact_s2[20, 3]),\n                                           \" (\", c(impact_s1[20, 6], impact_s2[20, 6]),\n                                           \" -- \", c(impact_s1[20, 9], impact_s2[20, 9]), \")\")\n                )\nnames(impact_results) <- c(\"Scenario\", \"Year 5\", \"Year 10\", \"Year 20\")\n\n\n# ---- impact_table -------------------------------------------------------\nx <- xtable(impact_results)\nprint(x, comment=FALSE, size = \"footnotesize\", floating=FALSE, include.rownames=FALSE, booktabs=TRUE)\n\n# ---- economics --------------------------------------------------------\n\n# Download and save CPI data\ncpi_url <- \"http://www.ausstats.abs.gov.au/ausstats/meisubs.nsf/0/7156D16BD1387570CA257FFC001338CB/$File/640101.xls\"\nif(!dir.exists(\"cpi\")){dir.create(\"cpi\")}\ndownload.file(cpi_url, \"cpi/cpi.xls\")\n\n# Load CPI data and calculate the percent increase from mid-year 2007 to current time\ncpi_data <- readxl::read_excel(\"cpi/cpi.xls\", sheet = 2, skip = 9)\ncpi_data <- cpi_data %>%\n  select(`Series ID`, A2325850V) %>%\n  filter(`Series ID` %within% interval(dmy(\"1/6/2007\"), Sys.Date()))\npercent_increase = sum(cpi_data[, 2])\n\n# Calcuate the current VSLY\nvsly_2007 <- 151000\nvsly_2016 <- vsly_2007 * (1 + (percent_increase / 100))\n\n# Function to estimate the present value of future gains in life\ncalculate_pv <- function(data, discount_rate, vsly){\n  data %>%\n    mutate(year = 1:nrow(.),\n           PV = vsly*life_years / (1 + discount_rate)^year,\n           cum_PV = cumsum(PV))\n}\n\ncalculate_pv(impact_s1[[1]], 0.07, vsly_2016)\n\npv_s1 <- lapply(impact_s1, FUN = calculate_pv, discount_rate = 0.07, vsly = vsly_2016)\npv_s2 <- lapply(impact_s2, FUN = calculate_pv, discount_rate = 0.07, vsly = vsly_2016)\npv_total <- lapply(impact_total, FUN = calculate_pv, discount_rate = 0.07, vsly = vsly_2016)\n\n# ---- figure_exposure ----------------------------------------------------\n\n# Load the study region SA1 map and simplify the geometry\nmap <- ap_poly\nmap@data$SA1_MAIN11 <- as.character(map@data$SA1_MAIN11)\nm1 <- fortify(map, region = \"SA1_MAIN11\")\nm1 <- left_join(m1, map@data, by = c(\"id\" = \"SA1_MAIN11\")) # Merge the data back on\nm1$all_heaters <- m1$s20 - m1$s21\nm1$s1 <- m1$s22 - m1$s21\nm1$s2 <- m1$s23 - m1$s21\n\n# Lengthen the data  so it's easy to make facets\nx <- m1 %>% gather(scenario, concentration, all_heaters, s1, s2)\n\n# Change factor names\nchange_name <- function(data, from, to) {\n  data$scenario <- replace(data$scenario, data$scenario == from, to)\n  data\n}\nx <- change_name(x, \"all_heaters\", \"2010/11 heater emissions\")\nx <- change_name(x, \"s1\", \"Heaters emit 2.5g/kg\")\nx <- change_name(x, \"s2\", \"Heaters emit 1.5g/kg\")\nx$scenario <- factor(x$scenario, levels = unique(x$scenario), ordered = TRUE)\n\n# To get NSW - load and simplify a map of Australia\naust <- readOGR(\"shp\", \"STE_2011_AUST\", verbose=FALSE)\nbg <- aust[aust$STE_CODE11 == 1, ] # It's the background\n# bg <- gSimplify(bg, tol = 0.01, topologyPreserve = TRUE)\nbg <- fortify(bg)\n\nsea1 <- data.frame(x = c(151, 151, 151.5, 151.5, 151),\n                   y = c(-34.3, -34.3, -34.8, -34.8, -34.3),\n                   group = rep(1, 5))\nsea2 <- data.frame(x = c(151.3, 151.3, 152, 152, 151.3),\n                   y = c(-34.8, -32.8, -32.8, -34.8, -34.8),\n                   group = rep(1, 5))\n\nggplot() +\n  geom_polygon(data = bg, aes(x = long, y = lat, group = group), fill = \"#DDDDDD\") +\n  geom_polygon(data = sea1, aes(x = x, y = y, group = group), fill = \"#FFFFFF\") +\n  geom_polygon(data = sea2, aes(x = x, y = y, group = group), fill = \"#FFFFFF\") +\n  geom_polygon(data = x, aes(x=long, y = lat, group = group, fill = concentration)) +\n  scale_fill_viridis(option = \"viridis\",\n                     name = expression(paste(\"P\", M[2.5],  \" (\", mu, \"g/\", m^3, \")\"))) +\n  facet_wrap(~scenario) +\n  coord_fixed(ratio = 1, xlim = c(150, 152.4), ylim = c(-34.8, -32.6))+\n  annotate(geom = \"text\", label = \"Sydney\", x = 151.44, y = -33.9, size = 2) +\n  annotate(geom = \"text\", x = 151.99, y = -32.95, label = \"Newcastle\", size = 2) +\n  annotate(geom = \"text\", x = 151.15, y = -34.5, label = \"Wollongong\", size = 2) +\n  theme_nothing(legend = TRUE) +\n  theme(text = element_text(family = \"libertine sans\"),\n        legend.position = c(1.02, -0.05),\n        legend.justification = c(1, 0),\n        legend.title = element_text(size = 5),\n        legend.text = element_text(size = 5),\n        legend.key.width = unit(0.3, \"cm\"),\n        legend.key.height = unit(0.5, \"cm\"),\n        strip.background = element_rect(fill = \"white\"),\n        strip.text = element_text(size = 8))\nrm(sea1, sea2, bg, change_name, map, m1, x)\n# ggsave(\"figure/figure_exposure.png\", units = \"cm\", width = 19.5, height = 7.2)\n\n\n# ---- figure_ses -----------------------------------------------------------\n\nx <- all_data %>%\n  filter(!is.na(irsd)) %>%\n  dplyr::select(-age, -population, -deaths) %>%\n  unique() %>%\n  mutate(no_heaters = all_anthropogenic - all_heaters) %>%\n  gather(scenario, concentration, -irsd, -gcc_code11) %>%\n  filter(scenario %in% c(\"all_heaters\", \"no_heaters\"), gcc_code11 == \"All NSW\") %>%\n  mutate(scenario = factor(scenario, labels = c(\"All heaters\", \"Anthropogenic (no heaters)\")))\n\n# x <- read.csv(\"data_for_analysis/irsd_exposure.csv\")\nggplot(x, aes(x = irsd, y = concentration)) + #, group = scenario)) +\n  geom_point() +\n  geom_smooth(span = 2, se = FALSE, colour = \"black\", size = 0.5) +\n  facet_wrap(~scenario, scales = \"free_y\") +\n  scale_x_continuous(breaks = 1:10) +\n  labs(\n    x = \"Decile of IRSD\",\n    y = expression(paste(\"P\", M[2.5], \" concentration (\", mu, \"g/\", m^3, \")\"))\n  ) +\n  theme_classic() +\n  theme(axis.line.x = element_line(size = 0.3),\n        axis.line.y = element_line(size = 0.3),\n        strip.background = element_rect(colour = \"white\"))\n\n\n",
    "created" : 1478040581843.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3741930569",
    "id" : "789B5579",
    "lastKnownWriteTime" : 1480048041,
    "last_content_update" : 1480048041261,
    "path" : "~/projects/wood_smoke_report/src/report_code.R",
    "project_path" : null,
    "properties" : {
        "docOutlineVisible" : "1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}